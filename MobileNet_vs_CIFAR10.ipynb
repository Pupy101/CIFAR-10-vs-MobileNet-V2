{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhL9v7L5ENHL"
      },
      "source": [
        "## CIFAR10 с MobileNet V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OvlSHyMcELid"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "from typing import Dict, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms as T\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ_WO6QxGSsb"
      },
      "source": [
        "### Загрузка данных\n",
        "#### Предобработка данных заключается в первоначальном изменении исходного изображения 32 х 32 до 224 х 224, так как это минимальные небходимый размер для сети MobileNetV2 из хаба pytorch, преобразовании их к тензору pytorch-а и приведению мат ожидания и дисперсии каждого канала изображения к следующим значенениям\n",
        "#### Для обучающего датасета также будут использоваться аугментации:\n",
        "1. ColorJitter\n",
        "2. RandomEqualize\n",
        "3. RandomHorizontalFlip и RandomVerticalFlip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imLNt7NGELlG",
        "outputId": "9fc2278c-0873-40df-ebc2-9c0366ff6658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "MEAN = [0.485, 0.456, 0.406]\n",
        "STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "transforms = {\n",
        "    'train': T.Compose([\n",
        "        T.Resize(224),\n",
        "        T.ColorJitter(brightness=.5, hue=.3),\n",
        "        T.RandomEqualize(),\n",
        "        T.RandomHorizontalFlip(),\n",
        "        T.RandomVerticalFlip(),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=MEAN, std=STD),\n",
        "    ]),\n",
        "    'valid': T.Compose([\n",
        "        T.Resize(224),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(mean=MEAN, std=STD),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "batch_sizes = {'train': 288, 'valid': 480}\n",
        "\n",
        "datasets = {\n",
        "    'train': datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms['train']),\n",
        "    'valid': datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms['valid']),\n",
        "}\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(datasets['train'], batch_size=batch_sizes['train'], shuffle=True, num_workers=2),\n",
        "    'valid': DataLoader(datasets['valid'], batch_size=batch_sizes['valid'], shuffle=False, num_workers=2),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b09FM8V_kbF-"
      },
      "source": [
        "### Функция обучения нейросети\n",
        "В функции осуществляется обучение и валидация.\n",
        "\n",
        "Входные параметры:\n",
        "1. Количество эпох;\n",
        "2. Модель;\n",
        "3. Оптимизатор;\n",
        "4. Функция потерь;\n",
        "5. Лоадер;\n",
        "6. Девайс;\n",
        "7. Скэжулер;\n",
        "8. Число шагов с аккамуляцией."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9hawvjwxEKWO"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "  num_epochs: int,\n",
        "  model: nn.Module,\n",
        "  optimizer: optim.Optimizer,\n",
        "  criterion: nn.Module,\n",
        "  loader: DataLoader,\n",
        "  device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "  scheduler = None,\n",
        "  accumulation: Optional[int] = 1,\n",
        "):\n",
        "  model = model.to(device)\n",
        "  min_eval_loss = float('inf')\n",
        "  for epoch in range(num_epochs):\n",
        "    train_loss = train_epoch(\n",
        "      model=model, optimizer=optimizer, criterion=criterion, loader=loader['train'],\n",
        "      device=device, scheduler=scheduler, accumulation=accumulation\n",
        "    )\n",
        "    eval_loss = valid_epoch(\n",
        "        model=model, criterion=criterion, loader=loader['valid'], device=device\n",
        "    )\n",
        "    if eval_loss < min_eval_loss:\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:>2}/{num_epochs}\\tTrain loss: {train_loss:<10.4f}\\tEval loss: {eval_loss:<10.4f}')\n",
        "\n",
        "  print(f'Best val Acc: {min_eval_loss:4f}')\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model\n",
        "\n",
        "def train_epoch(\n",
        "  model: nn.Module,\n",
        "  optimizer: optim.Optimizer,\n",
        "  criterion: nn.Module,\n",
        "  loader: Dict[str, DataLoader],\n",
        "  device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "  scheduler = None,\n",
        "  accumulation: Optional[int] = 1,\n",
        "):\n",
        "  model = model.train().to(device)\n",
        "  total_loss = 0\n",
        "  len_dataloader = len(loader)\n",
        "\n",
        "  for i, (imgs, labels) in tqdm(enumerate(loader, 1), leave=False, total=len_dataloader):\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(imgs)\n",
        "\n",
        "    loss = criterion(logits, labels)\n",
        "    loss.backward()\n",
        "    \n",
        "    if not i % accumulation or i == len_dataloader:\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      if scheduler is not None:\n",
        "        scheduler.step()\n",
        "    \n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len_dataloader\n",
        "\n",
        "@torch.no_grad()\n",
        "def valid_epoch(\n",
        "  model: nn.Module,\n",
        "  criterion: nn.Module,\n",
        "  loader: DataLoader,\n",
        "  device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "):\n",
        "  model = model.eval().to(device)\n",
        "  total_loss = 0\n",
        "  len_dataloader = len(loader)\n",
        "\n",
        "  for imgs, labels in tqdm(loader, leave=False, total=len_dataloader):\n",
        "    imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "    logits = model(imgs)\n",
        "\n",
        "    loss = criterion(logits, labels)\n",
        "    \n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJq6mCBr2TuX"
      },
      "source": [
        "### Модель\n",
        "\n",
        "Для обучения была взята MobileNetV2.\n",
        "\n",
        "Изменена последняя часть сети - классификатор. Также были заморожены первые слои метки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mzRrTUTpCpfF"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'mobilenet_v2', pretrained=True)\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "  nn.Dropout(p=0.1),\n",
        "  nn.Linear(in_features=1280, out_features=128),\n",
        "  nn.LeakyReLU(0.05),\n",
        "  nn.Dropout(p=0.1),\n",
        "  nn.Linear(in_features=128, out_features=10),\n",
        ")\n",
        "\n",
        "freeze_layer = 15\n",
        "for x in list(model.features.parameters())[:freeze_layer]:\n",
        "  x.requires_grad = False\n",
        "for x in list(model.features[freeze_layer:].parameters())[freeze_layer:]:\n",
        "  x.requires_grad = True\n",
        "for x in model.classifier.parameters():\n",
        "  x.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Параметры обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1mRgz549FRLH"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "optimizer = optim.AdamW(list(model.parameters())[freeze_layer:], lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "accumulation = 2\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UKHbFuCFRiE",
        "outputId": "ab452d36-0ee1-4015-881a-91ef954dbeeb"
      },
      "outputs": [],
      "source": [
        "best_model = train(num_epochs, model, optimizer, criterion, loaders, device, accumulation=accumulation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCnd9_BR4PwO"
      },
      "source": [
        "### Построение матрицы классификации на валидационном датасете"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7TdmqXXC-n9D"
      },
      "outputs": [],
      "source": [
        "def compute_confusion_matrix(model, loader):\n",
        "  conf_matrix = np.zeros((10, 10))\n",
        "  for inputs, labels in tqdm(loader, leave=False):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    logits = model(inputs)\n",
        "\n",
        "    preds = torch.argmax(logits, dim=1)\n",
        "    conf_matrix += confusion_matrix(\n",
        "      labels.cpu().numpy(), preds.cpu().numpy()\n",
        "    )\n",
        "  return conf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "_DgflWngtI3v",
        "outputId": "ee96d5df-3e01-4a19-f3bf-fcaddcc6615d"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "best_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0pA__I6wxtKZ"
      },
      "outputs": [],
      "source": [
        "conf_m = pd.DataFrame(compute_confusion_matrix(best_model, loaders['train']), index=classes, columns=classes)\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(conf_m, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_m = pd.DataFrame(compute_confusion_matrix(best_model, loaders['valid']), index=classes, columns=classes)\n",
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(conf_m, annot=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
